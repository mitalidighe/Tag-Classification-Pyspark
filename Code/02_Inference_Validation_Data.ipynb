{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a96440-eab9-48f3-b8f1-f41b2fbf9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c3818f-3fab-4eb3-a98b-2b27d56cd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Spark session\n",
    "spark = SparkSession.builder.appName('Stackoverflow_Project').getOrCreate()\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), \n",
    "                                        ('spark.app.name', 'Spark Updated Conf'), \n",
    "                                        ('spark.executor.cores', '4'), \n",
    "                                        ('spark.cores.max', '4'), \n",
    "                                        ('spark.driver.memory','8g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb829fab-85a6-4937-a1c3-ac6885e4e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Stackoverflow_Project\")\n",
    "    .config(\"spark.yarn.maxAppAttempts\", \"4\") \n",
    "    .config(\"spark.yarn.am.attemptFailuresValidityInterval\", \"1h\")  \n",
    "    .config(\"spark.task.maxFailures\", \"4\")  \n",
    "    .config(\"spark.executor.instances\", \"5\")  \n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"2\")\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"10\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), \n",
    "                                        ('spark.app.name', 'Spark Updated Conf'), \n",
    "                                        ('spark.executor.cores', '4'), \n",
    "                                        ('spark.cores.max', '4'), \n",
    "                                        ('spark.driver.memory','10g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a008f152-182c-4c79-91b0-6d60ebd0e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Read the cleaned and pre-processed data from the GCS bucket\n",
    "df = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .parquet(\"gs://msca-bdp-student-gcs/Group6/extracted_StackOverflow.parquet\",inferSchema=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5313924e-f7b9-418a-98f0-ecefe89675ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:==================================================>      (25 + 3) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+\n",
      "|      post_body_text|           post_tags|Count of Answers|\n",
      "+--------------------+--------------------+----------------+\n",
      "| i only want to p...|javascript|angularjs|               6|\n",
      "| i have a table t...|           php|mysql|               7|\n",
      "| please check the...|     html|css|colors|               5|\n",
      "| not sure if i am...|          python|gis|               7|\n",
      "| just learning jq...|javascript|jquery...|               5|\n",
      "+--------------------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Data is at answers level, aggregate to get at post level\n",
    "df_2 = df.select('post_body_text','post_tags') \\\n",
    "         .groupBy('post_body_text','post_tags').count()\n",
    "\n",
    "df_2 = df_2.withColumnRenamed('count', 'Count of Answers')\n",
    "df_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56d078e-4b7d-4fec-a161-11b5263545bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.repartition(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b495e377-5b0b-4d3a-b40e-f8f149b6d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "367336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df_2.filter(df_2[\"post_body_text\"].isNotNull())\n",
    "df_2 = df_2.dropDuplicates([\"post_body_text\"])\n",
    "df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7c7148-9cba-48cb-a9d0-690fe9203726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode, col, lit, array_contains\n",
    "\n",
    "#Split tags into an array\n",
    "df_2 = df_2.withColumn(\"tags_array\", split(col(\"post_tags\"), \"\\|\"))\n",
    "\n",
    "#Explode tags and count frequencies\n",
    "exploded_df = df_2.select('post_body_text','post_tags',explode(col(\"tags_array\")).alias(\"tag\"))\n",
    "tag_counts = exploded_df.groupBy(\"tag\").count().orderBy(col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719ee9f2-c4aa-4a90-98b6-35fbcbb9fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:===========================================>            (31 + 8) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|      post_body_text|           post_tags|                tag|\n",
      "+--------------------+--------------------+-------------------+\n",
      "| a beginner quest...|build-process|dev...|      build-process|\n",
      "| a beginner quest...|build-process|dev...|development-process|\n",
      "| a few years ago ...|                perl|               perl|\n",
      "| a friend told me...|c++|performance|c...|                c++|\n",
      "| a friend told me...|c++|performance|c...|        performance|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "exploded_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4633da-ee05-4221-a11d-c50aa3a605e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Select top 50 tags\n",
    "top_50_tags = tag_counts.limit(50).select(\"tag\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa42c9a-41e0-4102-862a-3f09ce62cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "502980"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter data for top 50 tags\n",
    "exploded_df_filtered = exploded_df.filter(col('tag').isin(top_50_tags))\n",
    "exploded_df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07333853-c2e1-4e4f-9dbf-8cddc6dc269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:===================>                                      (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_body_text: string (nullable = true)\n",
      " |-- post_tags: string (nullable = true)\n",
      " |-- .net: long (nullable = true)\n",
      " |-- ajax: long (nullable = true)\n",
      " |-- algorithm: long (nullable = true)\n",
      " |-- android: long (nullable = true)\n",
      " |-- arrays: long (nullable = true)\n",
      " |-- asp.net: long (nullable = true)\n",
      " |-- asp.net-mvc: long (nullable = true)\n",
      " |-- bash: long (nullable = true)\n",
      " |-- c: long (nullable = true)\n",
      " |-- c#: long (nullable = true)\n",
      " |-- c++: long (nullable = true)\n",
      " |-- class: long (nullable = true)\n",
      " |-- css: long (nullable = true)\n",
      " |-- database: long (nullable = true)\n",
      " |-- eclipse: long (nullable = true)\n",
      " |-- function: long (nullable = true)\n",
      " |-- html: long (nullable = true)\n",
      " |-- ios: long (nullable = true)\n",
      " |-- iphone: long (nullable = true)\n",
      " |-- java: long (nullable = true)\n",
      " |-- javascript: long (nullable = true)\n",
      " |-- jquery: long (nullable = true)\n",
      " |-- json: long (nullable = true)\n",
      " |-- language-agnostic: long (nullable = true)\n",
      " |-- linq: long (nullable = true)\n",
      " |-- linux: long (nullable = true)\n",
      " |-- list: long (nullable = true)\n",
      " |-- multithreading: long (nullable = true)\n",
      " |-- mysql: long (nullable = true)\n",
      " |-- objective-c: long (nullable = true)\n",
      " |-- oop: long (nullable = true)\n",
      " |-- performance: long (nullable = true)\n",
      " |-- perl: long (nullable = true)\n",
      " |-- php: long (nullable = true)\n",
      " |-- pointers: long (nullable = true)\n",
      " |-- python: long (nullable = true)\n",
      " |-- regex: long (nullable = true)\n",
      " |-- ruby: long (nullable = true)\n",
      " |-- ruby-on-rails: long (nullable = true)\n",
      " |-- sql: long (nullable = true)\n",
      " |-- sql-server: long (nullable = true)\n",
      " |-- string: long (nullable = true)\n",
      " |-- tsql: long (nullable = true)\n",
      " |-- vb.net: long (nullable = true)\n",
      " |-- visual-studio: long (nullable = true)\n",
      " |-- windows: long (nullable = true)\n",
      " |-- winforms: long (nullable = true)\n",
      " |-- wpf: long (nullable = true)\n",
      " |-- xcode: long (nullable = true)\n",
      " |-- xml: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Pivot data\n",
    "exploded_df_filtered = exploded_df_filtered.groupBy(\"post_body_text\",\"post_tags\").pivot(\"tag\").count()\n",
    "exploded_df_filtered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df755c34-570d-46b5-b242-ae62ecbae110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dot character triggers an error when used in column names. So rename these columns.\n",
    "exploded_df_filtered = exploded_df_filtered.withColumnRenamed('.net', 'dot_net')\n",
    "exploded_df_filtered = exploded_df_filtered.withColumnRenamed('asp.net-mvc', 'asp_dot_net-mvc')\n",
    "exploded_df_filtered = exploded_df_filtered.withColumnRenamed('asp.net', 'asp_dot_net')\n",
    "exploded_df_filtered = exploded_df_filtered.withColumnRenamed('vb.net', 'vb_dot_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "891782a2-92de-4d2e-b988-3ee028531ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['java',\n",
       " 'c#',\n",
       " 'javascript',\n",
       " 'php',\n",
       " 'c++',\n",
       " 'jquery',\n",
       " 'html',\n",
       " 'python',\n",
       " 'css',\n",
       " 'android',\n",
       " 'c',\n",
       " 'sql',\n",
       " 'mysql',\n",
       " 'arrays',\n",
       " 'string',\n",
       " 'sql-server',\n",
       " 'iphone',\n",
       " 'ios',\n",
       " 'regex',\n",
       " 'objective-c',\n",
       " 'algorithm',\n",
       " 'ruby',\n",
       " 'performance',\n",
       " 'database',\n",
       " 'linux',\n",
       " 'ruby-on-rails',\n",
       " 'windows',\n",
       " 'list',\n",
       " 'multithreading',\n",
       " 'oop',\n",
       " 'bash',\n",
       " 'eclipse',\n",
       " 'ajax',\n",
       " 'perl',\n",
       " 'json',\n",
       " 'pointers',\n",
       " 'visual-studio',\n",
       " 'xml',\n",
       " 'winforms',\n",
       " 'linq',\n",
       " 'function',\n",
       " 'class',\n",
       " 'tsql',\n",
       " 'wpf',\n",
       " 'xcode',\n",
       " 'language-agnostic',\n",
       " 'asp_dot_net',\n",
       " 'asp_dot_net-mvc',\n",
       " 'vb_dot_net',\n",
       " 'dot_net']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Also rename in tags list\n",
    "top_50_tags.remove('.net')\n",
    "top_50_tags.remove('asp.net-mvc')\n",
    "top_50_tags.remove('asp.net')\n",
    "top_50_tags.remove('vb.net')\n",
    "top_50_tags = top_50_tags + ['asp_dot_net','asp_dot_net-mvc','vb_dot_net','dot_net']\n",
    "top_50_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59039403-4528-4864-9cc8-35082b067fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:32:34 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 86:============================================>           (32 + 8) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n",
      "|      post_body_text|           post_tags|dot_net|ajax|algorithm|android|arrays|asp_dot_net|asp_dot_net-mvc|bash|  c| c#|c++|class|css|database|eclipse|function|html|ios|iphone|java|javascript|jquery|json|language-agnostic|linq|linux|list|multithreading|mysql|objective-c|oop|performance|perl|php|pointers|python|regex|ruby|ruby-on-rails|sql|sql-server|string|tsql|vb_dot_net|visual-studio|windows|winforms|wpf|xcode|xml|\n",
      "+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n",
      "| a few years ago ...|                perl|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   1|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n",
      "| a friend told me...|c++|performance|c...|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  1|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          1|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n",
      "| a net program is...|     c#|.net|clr|jit|      1|   0|        0|      0|     0|          0|              0|   0|  0|  1|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n",
      "| a sequence is bi...|           algorithm|      0|   0|        1|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n",
      "| a string is an a...|                 php|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  1|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n",
      "+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Since there are lot of null values because of pivoting the df, fill null values with 0s\n",
    "exploded_df_filtered = exploded_df_filtered.na.fill(value = 0)\n",
    "exploded_df_filtered.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1424586-b5b0-464a-b160-6aa6a72fa9c8",
   "metadata": {},
   "source": [
    "### Create pipeline for feature engineering/data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a24bc76b-f7eb-4795-a9e5-a9c80a4cf93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark ML imports\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Tokenize the data into words\n",
    "tokenizer = Tokenizer(inputCol=\"post_body_text\", outputCol=\"Words\")\n",
    "\n",
    "#Remove stop words\n",
    "remove_stopwords = StopWordsRemover(inputCol=\"Words\", outputCol=\"Filtered_Words\")\n",
    "\n",
    "#HashingTF\n",
    "hashing_tf = HashingTF(inputCol=\"Filtered_Words\", outputCol=\"Hashing_TF_Features\")\n",
    "\n",
    "#IDF\n",
    "idf = IDF(inputCol=\"Hashing_TF_Features\", outputCol=\"Hashing_TFIDF_Features\")\n",
    "\n",
    "#Creating a pipeline to transform the data and prepare it for the model\n",
    "pipeline = Pipeline(stages=[tokenizer, remove_stopwords, hashing_tf, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81d763d3-e4bd-4bab-9a75-03cb21a27cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:===================================================> (195 + 5) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_body_text: string (nullable = true)\n",
      " |-- post_tags: string (nullable = true)\n",
      " |-- dot_net: long (nullable = true)\n",
      " |-- ajax: long (nullable = true)\n",
      " |-- algorithm: long (nullable = true)\n",
      " |-- android: long (nullable = true)\n",
      " |-- arrays: long (nullable = true)\n",
      " |-- asp_dot_net: long (nullable = true)\n",
      " |-- asp_dot_net-mvc: long (nullable = true)\n",
      " |-- bash: long (nullable = true)\n",
      " |-- c: long (nullable = true)\n",
      " |-- c#: long (nullable = true)\n",
      " |-- c++: long (nullable = true)\n",
      " |-- class: long (nullable = true)\n",
      " |-- css: long (nullable = true)\n",
      " |-- database: long (nullable = true)\n",
      " |-- eclipse: long (nullable = true)\n",
      " |-- function: long (nullable = true)\n",
      " |-- html: long (nullable = true)\n",
      " |-- ios: long (nullable = true)\n",
      " |-- iphone: long (nullable = true)\n",
      " |-- java: long (nullable = true)\n",
      " |-- javascript: long (nullable = true)\n",
      " |-- jquery: long (nullable = true)\n",
      " |-- json: long (nullable = true)\n",
      " |-- language-agnostic: long (nullable = true)\n",
      " |-- linq: long (nullable = true)\n",
      " |-- linux: long (nullable = true)\n",
      " |-- list: long (nullable = true)\n",
      " |-- multithreading: long (nullable = true)\n",
      " |-- mysql: long (nullable = true)\n",
      " |-- objective-c: long (nullable = true)\n",
      " |-- oop: long (nullable = true)\n",
      " |-- performance: long (nullable = true)\n",
      " |-- perl: long (nullable = true)\n",
      " |-- php: long (nullable = true)\n",
      " |-- pointers: long (nullable = true)\n",
      " |-- python: long (nullable = true)\n",
      " |-- regex: long (nullable = true)\n",
      " |-- ruby: long (nullable = true)\n",
      " |-- ruby-on-rails: long (nullable = true)\n",
      " |-- sql: long (nullable = true)\n",
      " |-- sql-server: long (nullable = true)\n",
      " |-- string: long (nullable = true)\n",
      " |-- tsql: long (nullable = true)\n",
      " |-- vb_dot_net: long (nullable = true)\n",
      " |-- visual-studio: long (nullable = true)\n",
      " |-- windows: long (nullable = true)\n",
      " |-- winforms: long (nullable = true)\n",
      " |-- wpf: long (nullable = true)\n",
      " |-- xcode: long (nullable = true)\n",
      " |-- xml: long (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Filtered_Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Hashing_TF_Features: vector (nullable = true)\n",
      " |-- Hashing_TFIDF_Features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Fit and transform the data using the pipeline\n",
    "pipeline_final = pipeline.fit(exploded_df_filtered)\n",
    "model_df = pipeline_final.transform(exploded_df_filtered)\n",
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0cbae50-56c6-4589-8aa0-c018d117265c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "318648"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove duplicates\n",
    "model_df = model_df.dropDuplicates([\"post_body_text\"])\n",
    "model_df = model_df.filter(model_df[\"post_body_text\"].isNotNull())\n",
    "model_df = model_df.filter(model_df[\"post_tags\"].isNotNull())\n",
    "model_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3641f7c5-84dd-4145-ae0d-d3dd26769a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train (70%), test (20%), and validation (10%) sets\n",
    "train_df, test_df, val_df = model_df.randomSplit([0.7, 0.2, 0.1], seed=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a92b00-5412-4303-bc85-c2a706c54b5f",
   "metadata": {},
   "source": [
    "### Load the models from GCS for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e2ad20-137d-417a-a9e2-f0bf24e30f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:33:22 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \n",
      "java.lang.InterruptedException\n",
      "\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n",
      "\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n",
      "\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n",
      "\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/12/01 19:33:52 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \n",
      "java.lang.InterruptedException\n",
      "\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n",
      "\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n",
      "\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n",
      "\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "loaded_models = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    tag = top_50_tags[i]\n",
    "\n",
    "    # Path to save the model in GCS\n",
    "    gcs_model_path = f'gs://msca-bdp-student-gcs/Group6/Tag_classification_models/Log_Reg_{tag}'\n",
    "\n",
    "    # Save the trained logistic regression model\n",
    "    loaded_model = LogisticRegressionModel.load(gcs_model_path)\n",
    "    \n",
    "    loaded_models.append({\n",
    "        \"tag\": tag,\n",
    "        \"Log_reg_htfidf_model\": loaded_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2817359-af40-4215-9bb1-3458165001e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'java',\n",
       " 'Log_reg_htfidf_model': LogisticRegressionModel: uid=LogisticRegression_1480097e889f, numClasses=2, numFeatures=262144}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11adc53d-f4e4-455e-a371-ff6d15597911",
   "metadata": {},
   "source": [
    "### Inference - Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20d1022c-a525-4bcf-9575-bdac4ab96c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:34:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32032"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove duplicates\n",
    "val_df = val_df.dropDuplicates([\"post_body_text\"])\n",
    "val_df = val_df.filter(val_df[\"post_body_text\"].isNotNull())\n",
    "val_df = val_df.filter(val_df[\"post_tags\"].isNotNull())\n",
    "val_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e80352b9-99f7-4d13-9a5b-2141c82d3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:34:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|      post_body_text|           post_tags|\n",
      "+--------------------+--------------------+\n",
      "| all thanks for t...|objective-c|array...|\n",
      "| am newbie in lar...|         php|laravel|\n",
      "| am using it in w...|jquery|wordpress|...|\n",
      "| are there any go...| java|python|parsing|\n",
      "| as the question ...|jquery|drop-down-...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data = val_df.select(\"post_body_text\",\"post_tags\")\n",
    "results_validation_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4877384-a7d0-46ef-9f4a-014e83784b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:34:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31986"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_validation_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1466bc2d-27f3-43bb-9c92-fdb431a5b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ac0fcf2-3a1b-498c-ae66-b33ab7adac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:36:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:37:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:37:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:37:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:38:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:38:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:38:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:38:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:39:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:39:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:39:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:40:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:40:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:40:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:40:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:41:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:41:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:41:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:41:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:42:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:42:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:42:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:43:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:43:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:43:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:43:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:43:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:43:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:44:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:44:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:44:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:44:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:44:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:44:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:45:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:45:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:45:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:45:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:45:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:45:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:46:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:46:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:46:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:46:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:46:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:47:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:47:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:47:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:47:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/01 19:47:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for i in range(0,50):\n",
    "    tag = loaded_models[i]['tag']\n",
    "    Log_reg_model = loaded_models[i]['Log_reg_htfidf_model']\n",
    "    predictions = Log_reg_model.transform(val_df)\n",
    "    predictions_column = predictions.select(\"post_body_text\",col(\"prediction\").alias(tag))\n",
    "    predictions_column = predictions_column.withColumnRenamed(\"post_body_text\",f\"post_body_text_{i}\")\n",
    "    \n",
    "    predictions_tags.append({\n",
    "        \"tag\":tag,\n",
    "        \"predictions_column\":predictions_column,\n",
    "        \"count_rows\":predictions_column.count()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "398f2ef6-9b03-4ac1-bc69-7be79b482f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'java',\n",
       "  'predictions_column': DataFrame[post_body_text_0: string, java: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'c#',\n",
       "  'predictions_column': DataFrame[post_body_text_1: string, c#: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'javascript',\n",
       "  'predictions_column': DataFrame[post_body_text_2: string, javascript: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'php',\n",
       "  'predictions_column': DataFrame[post_body_text_3: string, php: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'c++',\n",
       "  'predictions_column': DataFrame[post_body_text_4: string, c++: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'jquery',\n",
       "  'predictions_column': DataFrame[post_body_text_5: string, jquery: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'html',\n",
       "  'predictions_column': DataFrame[post_body_text_6: string, html: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'python',\n",
       "  'predictions_column': DataFrame[post_body_text_7: string, python: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'css',\n",
       "  'predictions_column': DataFrame[post_body_text_8: string, css: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'android',\n",
       "  'predictions_column': DataFrame[post_body_text_9: string, android: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'c',\n",
       "  'predictions_column': DataFrame[post_body_text_10: string, c: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'sql',\n",
       "  'predictions_column': DataFrame[post_body_text_11: string, sql: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'mysql',\n",
       "  'predictions_column': DataFrame[post_body_text_12: string, mysql: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'arrays',\n",
       "  'predictions_column': DataFrame[post_body_text_13: string, arrays: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'string',\n",
       "  'predictions_column': DataFrame[post_body_text_14: string, string: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'sql-server',\n",
       "  'predictions_column': DataFrame[post_body_text_15: string, sql-server: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'iphone',\n",
       "  'predictions_column': DataFrame[post_body_text_16: string, iphone: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'ios',\n",
       "  'predictions_column': DataFrame[post_body_text_17: string, ios: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'regex',\n",
       "  'predictions_column': DataFrame[post_body_text_18: string, regex: double],\n",
       "  'count_rows': 31986},\n",
       " {'tag': 'objective-c',\n",
       "  'predictions_column': DataFrame[post_body_text_19: string, objective-c: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'algorithm',\n",
       "  'predictions_column': DataFrame[post_body_text_20: string, algorithm: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'ruby',\n",
       "  'predictions_column': DataFrame[post_body_text_21: string, ruby: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'performance',\n",
       "  'predictions_column': DataFrame[post_body_text_22: string, performance: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'database',\n",
       "  'predictions_column': DataFrame[post_body_text_23: string, database: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'linux',\n",
       "  'predictions_column': DataFrame[post_body_text_24: string, linux: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'ruby-on-rails',\n",
       "  'predictions_column': DataFrame[post_body_text_25: string, ruby-on-rails: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'windows',\n",
       "  'predictions_column': DataFrame[post_body_text_26: string, windows: double],\n",
       "  'count_rows': 32001},\n",
       " {'tag': 'list',\n",
       "  'predictions_column': DataFrame[post_body_text_27: string, list: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'multithreading',\n",
       "  'predictions_column': DataFrame[post_body_text_28: string, multithreading: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'oop',\n",
       "  'predictions_column': DataFrame[post_body_text_29: string, oop: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'bash',\n",
       "  'predictions_column': DataFrame[post_body_text_30: string, bash: double],\n",
       "  'count_rows': 32001},\n",
       " {'tag': 'eclipse',\n",
       "  'predictions_column': DataFrame[post_body_text_31: string, eclipse: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'ajax',\n",
       "  'predictions_column': DataFrame[post_body_text_32: string, ajax: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'perl',\n",
       "  'predictions_column': DataFrame[post_body_text_33: string, perl: double],\n",
       "  'count_rows': 32001},\n",
       " {'tag': 'json',\n",
       "  'predictions_column': DataFrame[post_body_text_34: string, json: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'pointers',\n",
       "  'predictions_column': DataFrame[post_body_text_35: string, pointers: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'visual-studio',\n",
       "  'predictions_column': DataFrame[post_body_text_36: string, visual-studio: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'xml',\n",
       "  'predictions_column': DataFrame[post_body_text_37: string, xml: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'winforms',\n",
       "  'predictions_column': DataFrame[post_body_text_38: string, winforms: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'linq',\n",
       "  'predictions_column': DataFrame[post_body_text_39: string, linq: double],\n",
       "  'count_rows': 32001},\n",
       " {'tag': 'function',\n",
       "  'predictions_column': DataFrame[post_body_text_40: string, function: double],\n",
       "  'count_rows': 32001},\n",
       " {'tag': 'class',\n",
       "  'predictions_column': DataFrame[post_body_text_41: string, class: double],\n",
       "  'count_rows': 32001},\n",
       " {'tag': 'tsql',\n",
       "  'predictions_column': DataFrame[post_body_text_42: string, tsql: double],\n",
       "  'count_rows': 32000},\n",
       " {'tag': 'wpf',\n",
       "  'predictions_column': DataFrame[post_body_text_43: string, wpf: double],\n",
       "  'count_rows': 32039},\n",
       " {'tag': 'xcode',\n",
       "  'predictions_column': DataFrame[post_body_text_44: string, xcode: double],\n",
       "  'count_rows': 31990},\n",
       " {'tag': 'language-agnostic',\n",
       "  'predictions_column': DataFrame[post_body_text_45: string, language-agnostic: double],\n",
       "  'count_rows': 31990},\n",
       " {'tag': 'asp_dot_net',\n",
       "  'predictions_column': DataFrame[post_body_text_46: string, asp_dot_net: double],\n",
       "  'count_rows': 31990},\n",
       " {'tag': 'asp_dot_net-mvc',\n",
       "  'predictions_column': DataFrame[post_body_text_47: string, asp_dot_net-mvc: double],\n",
       "  'count_rows': 31990},\n",
       " {'tag': 'vb_dot_net',\n",
       "  'predictions_column': DataFrame[post_body_text_48: string, vb_dot_net: double],\n",
       "  'count_rows': 31989},\n",
       " {'tag': 'dot_net',\n",
       "  'predictions_column': DataFrame[post_body_text_49: string, dot_net: double],\n",
       "  'count_rows': 31990}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d63a5588-5a6c-4a2c-868d-b4c81de5f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java : 31986\n",
      "c# : 31986\n",
      "javascript : 31986\n",
      "php : 31986\n",
      "c++ : 31986\n",
      "jquery : 31986\n",
      "html : 31986\n",
      "python : 31986\n",
      "css : 31986\n",
      "android : 31986\n",
      "c : 31986\n",
      "sql : 31986\n",
      "mysql : 31986\n",
      "arrays : 31986\n",
      "string : 31986\n",
      "sql-server : 31986\n",
      "iphone : 31986\n",
      "ios : 31986\n",
      "regex : 31986\n",
      "objective-c : 32000\n",
      "algorithm : 32000\n",
      "ruby : 32000\n",
      "performance : 32000\n",
      "database : 32000\n",
      "linux : 32000\n",
      "ruby-on-rails : 32000\n",
      "windows : 32001\n",
      "list : 32000\n",
      "multithreading : 32000\n",
      "oop : 32000\n",
      "bash : 32001\n",
      "eclipse : 32000\n",
      "ajax : 32000\n",
      "perl : 32001\n",
      "json : 32000\n",
      "pointers : 32000\n",
      "visual-studio : 32000\n",
      "xml : 32000\n",
      "winforms : 32000\n",
      "linq : 32001\n",
      "function : 32001\n",
      "class : 32001\n",
      "tsql : 32000\n",
      "wpf : 32039\n",
      "xcode : 31990\n",
      "language-agnostic : 31990\n",
      "asp_dot_net : 31990\n",
      "asp_dot_net-mvc : 31990\n",
      "vb_dot_net : 31989\n",
      "dot_net : 31990\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,50):\n",
    "    print(predictions_tags[i]['tag'],\":\",predictions_tags[i]['count_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70035278-c48d-4ad8-ad0d-1b6fa4274f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed iteration0\n",
      "completed iteration1\n",
      "completed iteration2\n",
      "completed iteration3\n",
      "completed iteration4\n",
      "completed iteration5\n",
      "completed iteration6\n",
      "completed iteration7\n",
      "completed iteration8\n",
      "completed iteration9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    #Join predictions back to the results DataFrame\n",
    "    predictions_column = predictions_tags[i]['predictions_column']\n",
    "    results_validation_data = results_validation_data.join(predictions_column, \n",
    "                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n",
    "                                                   how='inner')  \n",
    "    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n",
    "    print(f'completed iteration{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4115ff0-121b-453c-a015-5d4a18738ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:51:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "[Stage 1079:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+\n",
      "|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+\n",
      "| am newbie in lar...|         php|laravel| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n",
      "| below is my conn...| c#|entity-framework| 0.0|1.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n",
      "| i am developing ...|android|google-pl...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    1.0|\n",
      "| i dont quite und...|php|model-view-co...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n",
      "| i followed the h...|android|unit-testing| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a115b962-bf47-4913-bcdb-90344cb6876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed iteration10\n",
      "completed iteration11\n",
      "completed iteration12\n",
      "completed iteration13\n",
      "completed iteration14\n",
      "completed iteration15\n",
      "completed iteration16\n",
      "completed iteration17\n",
      "completed iteration18\n",
      "completed iteration19\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    #Join predictions back to the results DataFrame\n",
    "    predictions_column = predictions_tags[i]['predictions_column']\n",
    "    results_validation_data = results_validation_data.join(predictions_column, \n",
    "                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n",
    "                                                   how='inner')  \n",
    "    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n",
    "    print(f'completed iteration{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90badd65-f3d1-4345-b4a4-caeab3f2ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:53:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:55:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "[Stage 1112:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+\n",
      "|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+\n",
      "| can anyone expla...|          javascript| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n",
      "| how can i write ...|                   c| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n",
      "| i have 2 importa...|     java|networking| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n",
      "| i have a form th...|javascript|jquery...| 0.0|0.0|       1.0|0.0|0.0|   1.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n",
      "| i have a text fi...|                  c#| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b7ace1c-14c7-4771-b6df-f9b05a23ed24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed iteration20\n",
      "completed iteration21\n",
      "completed iteration22\n",
      "completed iteration23\n",
      "completed iteration24\n",
      "completed iteration25\n",
      "completed iteration26\n",
      "completed iteration27\n",
      "completed iteration28\n",
      "completed iteration29\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,30):\n",
    "    #Join predictions back to the results DataFrame\n",
    "    predictions_column = predictions_tags[i]['predictions_column']\n",
    "    results_validation_data = results_validation_data.join(predictions_column, \n",
    "                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n",
    "                                                   how='inner')  \n",
    "    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n",
    "    print(f'completed iteration{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a46f1d0-0d02-49de-aa34-700405187143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:58:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "[Stage 1155:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+\n",
      "|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|algorithm|ruby|performance|database|linux|ruby-on-rails|windows|list|multithreading|oop|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+\n",
      "| i am trying to s...|          javascript| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 1.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n",
      "| i have a form th...|javascript|jquery...| 0.0|0.0|       1.0|0.0|0.0|   1.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n",
      "| i have a propert...|c#|sorting|hashtable| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n",
      "| i have a variabl...|                 php| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n",
      "| i have this piec...|javascript|decrem...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7850f2c2-27d7-42db-a794-f196733bd26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed iteration30\n",
      "completed iteration31\n",
      "completed iteration32\n",
      "completed iteration33\n",
      "completed iteration34\n",
      "completed iteration35\n",
      "completed iteration36\n",
      "completed iteration37\n",
      "completed iteration38\n",
      "completed iteration39\n"
     ]
    }
   ],
   "source": [
    "for i in range(30,40):\n",
    "    #Join predictions back to the results DataFrame\n",
    "    predictions_column = predictions_tags[i]['predictions_column']\n",
    "    results_validation_data = results_validation_data.join(predictions_column, \n",
    "                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n",
    "                                                   how='inner')  \n",
    "    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n",
    "    print(f'completed iteration{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f406f8b-d7d0-46cd-aa7f-eb3fba5b98c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:01:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "[Stage 1208:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+\n",
      "|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|algorithm|ruby|performance|database|linux|ruby-on-rails|windows|list|multithreading|oop|bash|eclipse|ajax|perl|json|pointers|visual-studio|xml|winforms|linq|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+\n",
      "| i am trying to s...|          javascript| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 1.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n",
      "| i have a form th...|javascript|jquery...| 0.0|0.0|       1.0|0.0|0.0|   1.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n",
      "| i have a propert...|c#|sorting|hashtable| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n",
      "| i have a variabl...|                 php| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n",
      "| i have this piec...|javascript|decrem...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d10fe89-2a47-412f-b1b4-cf3aa1d150b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed iteration40\n",
      "completed iteration41\n",
      "completed iteration42\n",
      "completed iteration43\n",
      "completed iteration44\n",
      "completed iteration45\n",
      "completed iteration46\n",
      "completed iteration47\n",
      "completed iteration48\n",
      "completed iteration49\n"
     ]
    }
   ],
   "source": [
    "for i in range(40,50):\n",
    "    #Join predictions back to the results DataFrame\n",
    "    predictions_column = predictions_tags[i]['predictions_column']\n",
    "    results_validation_data = results_validation_data.join(predictions_column, \n",
    "                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n",
    "                                                   how='inner')  \n",
    "    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n",
    "    print(f'completed iteration{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ab497d8-3b13-4ff9-a255-8727d5cd4d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 20:01:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:01:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:01:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:04:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "[Stage 1271:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+--------+-----+----+---+-----+-----------------+-----------+---------------+----------+-------+\n",
      "|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|algorithm|ruby|performance|database|linux|ruby-on-rails|windows|list|multithreading|oop|bash|eclipse|ajax|perl|json|pointers|visual-studio|xml|winforms|linq|function|class|tsql|wpf|xcode|language-agnostic|asp_dot_net|asp_dot_net-mvc|vb_dot_net|dot_net|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+--------+-----+----+---+-----+-----------------+-----------+---------------+----------+-------+\n",
      "| am newbie in lar...|         php|laravel| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n",
      "| for example i am...|java|static|non-s...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n",
      "| how can i close ...|c#|winforms|keybo...| 0.0|1.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   1.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     1.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n",
      "| how can i filter...|linux|bash|sed|aw...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n",
      "| i am completely ...|         c#|xml|linq| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|1.0|     0.0| 1.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n",
      "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+--------+-----+----+---+-----+-----------------+-----------+---------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6555348d-9a93-498f-b1ff-87004a917f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 20:04:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame to GCS in Parquet format\n",
    "output_path1 = \"gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/val_df\"\n",
    "val_df.write.mode(\"overwrite\").parquet(output_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ceb218a7-2c4c-4049-be1c-c314a389f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 20:05:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:07:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame to GCS in Parquet format\n",
    "output_path2 = \"gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/results_validation_data\"\n",
    "results_validation_data.write.mode(\"overwrite\").parquet(output_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9428c6ec-91df-4b3f-bfd0-26854db2fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 20:09:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:11:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 91.5 MiB\n",
      "[Stage 1407:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|      post_body_text|           post_tags|      predicted_tags|\n",
      "+--------------------+--------------------+--------------------+\n",
      "| am newbie in lar...|         php|laravel|               [php]|\n",
      "| how can i close ...|c#|winforms|keybo...|[c#, string, winf...|\n",
      "| i am completely ...|         c#|xml|linq|         [xml, linq]|\n",
      "| i have django in...| python|django|pydev|            [python]|\n",
      "| i have problem w...|python|file|dicti...|            [python]|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#We can also have a look at some of the tags that the model has been able to generate for posts by condensing the data\n",
    "from pyspark.sql.functions import array, col, when, expr, size\n",
    "\n",
    "results_validation_data_with_tags = results_validation_data.withColumn(\"predicted_tags\",array(*[when(col(tag) == 1, \n",
    "                                                                                          tag).otherwise(None) \n",
    "                                                                                     for tag in top_50_tags]))\n",
    "\n",
    "results_validation_data_with_tags = results_validation_data_with_tags.withColumn(\"predicted_tags\",\n",
    "                                                                                 expr(\"filter(predicted_tags, x -> x is not null)\"))\n",
    "\n",
    "results_validation_data_with_tags.filter(size(col(\"predicted_tags\")) > 0).select('post_body_text','post_tags','predicted_tags').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9780576f-d89e-43ec-8984-b2c34eb44a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:12:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "24/12/01 20:14:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 91.8 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame to GCS in Parquet format\n",
    "output_path3 = \"gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/results_validation_data_with_tags\"\n",
    "results_validation_data_with_tags.write.mode(\"overwrite\").parquet(output_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8c81f5a-e2b7-48e3-9ba2-4f16ce1615bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_body_text: string (nullable = true)\n",
      " |-- post_tags: string (nullable = true)\n",
      " |-- java: double (nullable = false)\n",
      " |-- c#: double (nullable = false)\n",
      " |-- javascript: double (nullable = false)\n",
      " |-- php: double (nullable = false)\n",
      " |-- c++: double (nullable = false)\n",
      " |-- jquery: double (nullable = false)\n",
      " |-- html: double (nullable = false)\n",
      " |-- python: double (nullable = false)\n",
      " |-- css: double (nullable = false)\n",
      " |-- android: double (nullable = false)\n",
      " |-- c: double (nullable = false)\n",
      " |-- sql: double (nullable = false)\n",
      " |-- mysql: double (nullable = false)\n",
      " |-- arrays: double (nullable = false)\n",
      " |-- string: double (nullable = false)\n",
      " |-- sql-server: double (nullable = false)\n",
      " |-- iphone: double (nullable = false)\n",
      " |-- ios: double (nullable = false)\n",
      " |-- regex: double (nullable = false)\n",
      " |-- objective-c: double (nullable = false)\n",
      " |-- algorithm: double (nullable = false)\n",
      " |-- ruby: double (nullable = false)\n",
      " |-- performance: double (nullable = false)\n",
      " |-- database: double (nullable = false)\n",
      " |-- linux: double (nullable = false)\n",
      " |-- ruby-on-rails: double (nullable = false)\n",
      " |-- windows: double (nullable = false)\n",
      " |-- list: double (nullable = false)\n",
      " |-- multithreading: double (nullable = false)\n",
      " |-- oop: double (nullable = false)\n",
      " |-- bash: double (nullable = false)\n",
      " |-- eclipse: double (nullable = false)\n",
      " |-- ajax: double (nullable = false)\n",
      " |-- perl: double (nullable = false)\n",
      " |-- json: double (nullable = false)\n",
      " |-- pointers: double (nullable = false)\n",
      " |-- visual-studio: double (nullable = false)\n",
      " |-- xml: double (nullable = false)\n",
      " |-- winforms: double (nullable = false)\n",
      " |-- linq: double (nullable = false)\n",
      " |-- function: double (nullable = false)\n",
      " |-- class: double (nullable = false)\n",
      " |-- tsql: double (nullable = false)\n",
      " |-- wpf: double (nullable = false)\n",
      " |-- xcode: double (nullable = false)\n",
      " |-- language-agnostic: double (nullable = false)\n",
      " |-- asp_dot_net: double (nullable = false)\n",
      " |-- asp_dot_net-mvc: double (nullable = false)\n",
      " |-- vb_dot_net: double (nullable = false)\n",
      " |-- dot_net: double (nullable = false)\n",
      " |-- predicted_tags: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_validation_data_with_tags.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bd34652-594b-46a5-bd9e-10580ce84bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 00:59:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 00:59:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/12/02 00:59:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/12/02 00:59:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/12/02 00:59:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/12/02 00:59:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|java|count|\n",
      "+----+-----+\n",
      "|   0|27436|\n",
      "|   1| 4665|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_df.groupBy('java').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e39ee65-1ef9-427e-a5f9-d30505f3c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 01:00:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/12/02 01:03:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n",
      "24/12/02 01:03:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n",
      "24/12/02 01:03:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n",
      "24/12/02 01:03:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n",
      "24/12/02 01:03:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n",
      "24/12/02 01:03:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|java|count|\n",
      "+----+-----+\n",
      "| 0.0|26899|\n",
      "| 1.0| 2880|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_validation_data.groupBy('java').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68924b64-1cd9-4fea-a4f8-ef42ae6096a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2bb57b-fa1a-4023-bdef-dbf30296faaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ab38d-1382-44e2-9936-56d99f02572b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de673a2-f440-4696-aa1e-9a982e7eec10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
