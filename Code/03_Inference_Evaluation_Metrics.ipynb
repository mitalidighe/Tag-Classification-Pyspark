{"cells": [{"cell_type": "code", "execution_count": 1, "id": "19a96440-eab9-48f3-b8f1-f41b2fbf9e8a", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\nimport matplotlib.pyplot as plt\n%matplotlib inline"}, {"cell_type": "code", "execution_count": 2, "id": "81c3818f-3fab-4eb3-a98b-2b27d56cd447", "metadata": {}, "outputs": [], "source": "#create Spark session\nspark = SparkSession.builder.appName('Stackoverflow_Project').getOrCreate()\n\n#change configuration settings on Spark \nconf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), \n                                        ('spark.app.name', 'Spark Updated Conf'), \n                                        ('spark.executor.cores', '4'), \n                                        ('spark.cores.max', '4'), \n                                        ('spark.driver.memory','8g')])"}, {"cell_type": "code", "execution_count": 3, "id": "cb829fab-85a6-4937-a1c3-ac6885e4e0ef", "metadata": {}, "outputs": [], "source": "spark = (\n    SparkSession.builder\n    .appName(\"Stackoverflow_Project\")\n    .config(\"spark.yarn.maxAppAttempts\", \"4\")  # Allow Spark job to retry\n    .config(\"spark.yarn.am.attemptFailuresValidityInterval\", \"1h\")  # Time window for retries\n    .config(\"spark.task.maxFailures\", \"4\")  # Retry failed tasks\n    .config(\"spark.executor.instances\", \"5\")  # Adjust to ensure redundancy\n    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n    .config(\"spark.dynamicAllocation.minExecutors\", \"2\")\n    .config(\"spark.dynamicAllocation.maxExecutors\", \"10\")\n    .getOrCreate()\n)\n\n#change configuration settings on Spark \nconf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), \n                                        ('spark.app.name', 'Spark Updated Conf'), \n                                        ('spark.executor.cores', '4'), \n                                        ('spark.cores.max', '4'), \n                                        ('spark.driver.memory','10g')])"}, {"cell_type": "code", "execution_count": 4, "id": "a008f152-182c-4c79-91b0-6d60ebd0e510", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Read the cleaned and pre-processed data from the GCS bucket\ndf = spark.read \\\n    .option(\"quote\", \"\\\"\")  \\\n    .option(\"escape\", \"\\\"\") \\\n    .option(\"ignoreLeadingWhiteSpace\",True) \\\n    .parquet(\"gs://msca-bdp-student-gcs/Group6/extracted_StackOverflow.parquet\",inferSchema=True, header=True )"}, {"cell_type": "code", "execution_count": 5, "id": "5313924e-f7b9-418a-98f0-ecefe89675ea", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----------------+\n|      post_body_text|           post_tags|Count of Answers|\n+--------------------+--------------------+----------------+\n| whats the availa...|php|linux|ms-word...|              10|\n| what is the best...|      c#|collections|              15|\n| i d like to run ...|java|algorithm|jv...|              10|\n| i m looking for ...|      python|math|3d|               9|\n| i have some c co...|java|c|pointers|b...|               6|\n+--------------------+--------------------+----------------+\nonly showing top 5 rows\n\n"}], "source": "#Data is at answers level, aggregate to get at post level\ndf_2 = df.select('post_body_text','post_tags') \\\n         .groupBy('post_body_text','post_tags').count()\n\ndf_2 = df_2.withColumnRenamed('count', 'Count of Answers')\ndf_2.show(5)"}, {"cell_type": "code", "execution_count": 6, "id": "c56d078e-4b7d-4fec-a161-11b5263545bd", "metadata": {}, "outputs": [], "source": "df_2 = df_2.repartition(40)"}, {"cell_type": "code", "execution_count": 7, "id": "b495e377-5b0b-4d3a-b40e-f8f149b6d538", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "367336"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "df_2 = df_2.filter(df_2[\"post_body_text\"].isNotNull())\ndf_2 = df_2.dropDuplicates([\"post_body_text\"])\ndf_2.count()"}, {"cell_type": "code", "execution_count": 8, "id": "6b7c7148-9cba-48cb-a9d0-690fe9203726", "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import split, explode, col, lit, array_contains\n\n#Split tags into an array\ndf_2 = df_2.withColumn(\"tags_array\", split(col(\"post_tags\"), \"\\|\"))\n\n#Explode tags and count frequencies\nexploded_df = df_2.select('post_body_text','post_tags',explode(col(\"tags_array\")).alias(\"tag\"))\ntag_counts = exploded_df.groupBy(\"tag\").count().orderBy(col(\"count\").desc())"}, {"cell_type": "code", "execution_count": 9, "id": "719ee9f2-c4aa-4a90-98b6-35fbcbb9fa51", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 24:==================================================>     (36 + 4) / 40]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+-------------------+\n|      post_body_text|           post_tags|                tag|\n+--------------------+--------------------+-------------------+\n| a beginner quest...|build-process|dev...|      build-process|\n| a beginner quest...|build-process|dev...|development-process|\n| a few years ago ...|                perl|               perl|\n| a friend told me...|c++|performance|c...|                c++|\n| a friend told me...|c++|performance|c...|        performance|\n+--------------------+--------------------+-------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "exploded_df.show(5)"}, {"cell_type": "code", "execution_count": 10, "id": "2c4633da-ee05-4221-a11d-c50aa3a605e5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Select top 50 tags\ntop_50_tags = tag_counts.limit(50).select(\"tag\").rdd.flatMap(lambda x: x).collect()"}, {"cell_type": "code", "execution_count": 11, "id": "2aa42c9a-41e0-4102-862a-3f09ce62cb68", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "502985"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "#Filter data for top 50 tags\nexploded_df_filtered = exploded_df.filter(col('tag').isin(top_50_tags))\nexploded_df_filtered.count()"}, {"cell_type": "code", "execution_count": 12, "id": "07333853-c2e1-4e4f-9dbf-8cddc6dc269f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 69:==================================>                       (3 + 2) / 5]\r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- post_body_text: string (nullable = true)\n |-- post_tags: string (nullable = true)\n |-- .net: long (nullable = true)\n |-- ajax: long (nullable = true)\n |-- algorithm: long (nullable = true)\n |-- android: long (nullable = true)\n |-- arrays: long (nullable = true)\n |-- asp.net: long (nullable = true)\n |-- asp.net-mvc: long (nullable = true)\n |-- bash: long (nullable = true)\n |-- c: long (nullable = true)\n |-- c#: long (nullable = true)\n |-- c++: long (nullable = true)\n |-- class: long (nullable = true)\n |-- css: long (nullable = true)\n |-- database: long (nullable = true)\n |-- eclipse: long (nullable = true)\n |-- function: long (nullable = true)\n |-- html: long (nullable = true)\n |-- ios: long (nullable = true)\n |-- iphone: long (nullable = true)\n |-- java: long (nullable = true)\n |-- javascript: long (nullable = true)\n |-- jquery: long (nullable = true)\n |-- json: long (nullable = true)\n |-- language-agnostic: long (nullable = true)\n |-- linq: long (nullable = true)\n |-- linux: long (nullable = true)\n |-- list: long (nullable = true)\n |-- multithreading: long (nullable = true)\n |-- mysql: long (nullable = true)\n |-- objective-c: long (nullable = true)\n |-- oop: long (nullable = true)\n |-- performance: long (nullable = true)\n |-- perl: long (nullable = true)\n |-- php: long (nullable = true)\n |-- pointers: long (nullable = true)\n |-- python: long (nullable = true)\n |-- regex: long (nullable = true)\n |-- ruby: long (nullable = true)\n |-- ruby-on-rails: long (nullable = true)\n |-- sql: long (nullable = true)\n |-- sql-server: long (nullable = true)\n |-- string: long (nullable = true)\n |-- tsql: long (nullable = true)\n |-- vb.net: long (nullable = true)\n |-- visual-studio: long (nullable = true)\n |-- windows: long (nullable = true)\n |-- winforms: long (nullable = true)\n |-- wpf: long (nullable = true)\n |-- xcode: long (nullable = true)\n |-- xml: long (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Pivot data\nexploded_df_filtered = exploded_df_filtered.groupBy(\"post_body_text\",\"post_tags\").pivot(\"tag\").count()\nexploded_df_filtered.printSchema()"}, {"cell_type": "code", "execution_count": 13, "id": "df755c34-570d-46b5-b242-ae62ecbae110", "metadata": {}, "outputs": [], "source": "#The dot character triggers an error when used in column names. So rename these columns.\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('.net', 'dot_net')\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('asp.net-mvc', 'asp_dot_net-mvc')\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('asp.net', 'asp_dot_net')\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('vb.net', 'vb_dot_net')"}, {"cell_type": "code", "execution_count": 14, "id": "891782a2-92de-4d2e-b988-3ee028531ebb", "metadata": {}, "outputs": [{"data": {"text/plain": "['java',\n 'c#',\n 'javascript',\n 'php',\n 'c++',\n 'jquery',\n 'html',\n 'python',\n 'css',\n 'android',\n 'c',\n 'sql',\n 'mysql',\n 'arrays',\n 'string',\n 'sql-server',\n 'iphone',\n 'ios',\n 'regex',\n 'objective-c',\n 'algorithm',\n 'ruby',\n 'performance',\n 'database',\n 'linux',\n 'ruby-on-rails',\n 'windows',\n 'list',\n 'multithreading',\n 'oop',\n 'bash',\n 'eclipse',\n 'ajax',\n 'perl',\n 'json',\n 'pointers',\n 'visual-studio',\n 'xml',\n 'winforms',\n 'linq',\n 'function',\n 'class',\n 'tsql',\n 'wpf',\n 'xcode',\n 'language-agnostic',\n 'asp_dot_net',\n 'asp_dot_net-mvc',\n 'vb_dot_net',\n 'dot_net']"}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": "#Also rename in tags list\ntop_50_tags.remove('.net')\ntop_50_tags.remove('asp.net-mvc')\ntop_50_tags.remove('asp.net')\ntop_50_tags.remove('vb.net')\ntop_50_tags = top_50_tags + ['asp_dot_net','asp_dot_net-mvc','vb_dot_net','dot_net']\ntop_50_tags"}, {"cell_type": "code", "execution_count": 15, "id": "59039403-4528-4864-9cc8-35082b067fe0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:26:40 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 86:============================================>           (32 + 4) / 40]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n|      post_body_text|           post_tags|dot_net|ajax|algorithm|android|arrays|asp_dot_net|asp_dot_net-mvc|bash|  c| c#|c++|class|css|database|eclipse|function|html|ios|iphone|java|javascript|jquery|json|language-agnostic|linq|linux|list|multithreading|mysql|objective-c|oop|performance|perl|php|pointers|python|regex|ruby|ruby-on-rails|sql|sql-server|string|tsql|vb_dot_net|visual-studio|windows|winforms|wpf|xcode|xml|\n+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n| a few years ago ...|                perl|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   1|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a friend told me...|c++|performance|c...|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  1|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          1|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a net program is...|     c#|.net|clr|jit|      1|   0|        0|      0|     0|          0|              0|   0|  0|  1|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a sequence is bi...|           algorithm|      0|   0|        1|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a string is an a...|                 php|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  1|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Since there are lot of null values because of pivoting the df, fill null values with 0s\nexploded_df_filtered = exploded_df_filtered.na.fill(value = 0)\nexploded_df_filtered.show(5)"}, {"cell_type": "markdown", "id": "b1424586-b5b0-464a-b160-6aa6a72fa9c8", "metadata": {}, "source": "### Create pipeline for feature engineering/data transformation"}, {"cell_type": "code", "execution_count": 16, "id": "a24bc76b-f7eb-4795-a9e5-a9c80a4cf93a", "metadata": {}, "outputs": [], "source": "#Spark ML imports\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n#Tokenize the data into words\ntokenizer = Tokenizer(inputCol=\"post_body_text\", outputCol=\"Words\")\n\n#Remove stop words\nremove_stopwords = StopWordsRemover(inputCol=\"Words\", outputCol=\"Filtered_Words\")\n\n#HashingTF\nhashing_tf = HashingTF(inputCol=\"Filtered_Words\", outputCol=\"Hashing_TF_Features\")\n\n#IDF\nidf = IDF(inputCol=\"Hashing_TF_Features\", outputCol=\"Hashing_TFIDF_Features\")\n\n#Creating a pipeline to transform the data and prepare it for the model\npipeline = Pipeline(stages=[tokenizer, remove_stopwords, hashing_tf, idf])"}, {"cell_type": "code", "execution_count": 17, "id": "81d763d3-e4bd-4bab-9a75-03cb21a27cb9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- post_body_text: string (nullable = true)\n |-- post_tags: string (nullable = true)\n |-- dot_net: long (nullable = true)\n |-- ajax: long (nullable = true)\n |-- algorithm: long (nullable = true)\n |-- android: long (nullable = true)\n |-- arrays: long (nullable = true)\n |-- asp_dot_net: long (nullable = true)\n |-- asp_dot_net-mvc: long (nullable = true)\n |-- bash: long (nullable = true)\n |-- c: long (nullable = true)\n |-- c#: long (nullable = true)\n |-- c++: long (nullable = true)\n |-- class: long (nullable = true)\n |-- css: long (nullable = true)\n |-- database: long (nullable = true)\n |-- eclipse: long (nullable = true)\n |-- function: long (nullable = true)\n |-- html: long (nullable = true)\n |-- ios: long (nullable = true)\n |-- iphone: long (nullable = true)\n |-- java: long (nullable = true)\n |-- javascript: long (nullable = true)\n |-- jquery: long (nullable = true)\n |-- json: long (nullable = true)\n |-- language-agnostic: long (nullable = true)\n |-- linq: long (nullable = true)\n |-- linux: long (nullable = true)\n |-- list: long (nullable = true)\n |-- multithreading: long (nullable = true)\n |-- mysql: long (nullable = true)\n |-- objective-c: long (nullable = true)\n |-- oop: long (nullable = true)\n |-- performance: long (nullable = true)\n |-- perl: long (nullable = true)\n |-- php: long (nullable = true)\n |-- pointers: long (nullable = true)\n |-- python: long (nullable = true)\n |-- regex: long (nullable = true)\n |-- ruby: long (nullable = true)\n |-- ruby-on-rails: long (nullable = true)\n |-- sql: long (nullable = true)\n |-- sql-server: long (nullable = true)\n |-- string: long (nullable = true)\n |-- tsql: long (nullable = true)\n |-- vb_dot_net: long (nullable = true)\n |-- visual-studio: long (nullable = true)\n |-- windows: long (nullable = true)\n |-- winforms: long (nullable = true)\n |-- wpf: long (nullable = true)\n |-- xcode: long (nullable = true)\n |-- xml: long (nullable = true)\n |-- Words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- Filtered_Words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- Hashing_TF_Features: vector (nullable = true)\n |-- Hashing_TFIDF_Features: vector (nullable = true)\n\n"}], "source": "#Fit and transform the data using the pipeline\npipeline_final = pipeline.fit(exploded_df_filtered)\nmodel_df = pipeline_final.transform(exploded_df_filtered)\nmodel_df.printSchema()"}, {"cell_type": "code", "execution_count": 18, "id": "f0cbae50-56c6-4589-8aa0-c018d117265c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "318649"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "#Remove duplicates\nmodel_df = model_df.dropDuplicates([\"post_body_text\"])\nmodel_df = model_df.filter(model_df[\"post_body_text\"].isNotNull())\nmodel_df = model_df.filter(model_df[\"post_tags\"].isNotNull())\nmodel_df.count()"}, {"cell_type": "code", "execution_count": 19, "id": "3641f7c5-84dd-4145-ae0d-d3dd26769a83", "metadata": {}, "outputs": [], "source": "# Split the data into train (70%), test (20%), and validation (10%) sets\ntrain_df, test_df, val_df = model_df.randomSplit([0.7, 0.2, 0.1], seed=11)"}, {"cell_type": "markdown", "id": "15a92b00-5412-4303-bc85-c2a706c54b5f", "metadata": {}, "source": "### Load the models from GCS for inference"}, {"cell_type": "code", "execution_count": 20, "id": "03e2ad20-137d-417a-a9e2-f0bf24e30f8b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:28:14 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n"}], "source": "loaded_models = []\n\nfor i in range(0,50):\n    tag = top_50_tags[i]\n\n    # Path to save the model in GCS\n    gcs_model_path = f'gs://msca-bdp-student-gcs/Group6/Tag_classification_models/Log_Reg_{tag}'\n\n    # Save the trained logistic regression model\n    loaded_model = LogisticRegressionModel.load(gcs_model_path)\n    \n    loaded_models.append({\n        \"tag\": tag,\n        \"Log_reg_htfidf_model\": loaded_model})"}, {"cell_type": "code", "execution_count": 21, "id": "c2817359-af40-4215-9bb1-3458165001e4", "metadata": {}, "outputs": [{"data": {"text/plain": "{'tag': 'java',\n 'Log_reg_htfidf_model': LogisticRegressionModel: uid=LogisticRegression_1480097e889f, numClasses=2, numFeatures=262144}"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "loaded_models[0]"}, {"cell_type": "markdown", "id": "11adc53d-f4e4-455e-a371-ff6d15597911", "metadata": {}, "source": "### Inference - Validation Data"}, {"cell_type": "code", "execution_count": 22, "id": "20d1022c-a525-4bcf-9575-bdac4ab96c7c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:28:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n                                                                                \r"}, {"data": {"text/plain": "31965"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "#Remove duplicates\nval_df = val_df.dropDuplicates([\"post_body_text\"])\nval_df = val_df.filter(val_df[\"post_body_text\"].isNotNull())\nval_df = val_df.filter(val_df[\"post_tags\"].isNotNull())\nval_df.count()"}, {"cell_type": "code", "execution_count": 23, "id": "e80352b9-99f7-4d13-9a5b-2141c82d3482", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:29:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|      post_body_text|           post_tags|\n+--------------------+--------------------+\n| all thanks for t...|objective-c|array...|\n| am newbie in lar...|         php|laravel|\n| am using it in w...|jquery|wordpress|...|\n| are there any go...| java|python|parsing|\n| as the question ...|jquery|drop-down-...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data = val_df.select(\"post_body_text\",\"post_tags\")\nresults_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 24, "id": "b4877384-a7d0-46ef-9f4a-014e83784b07", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:29:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n                                                                                \r"}, {"data": {"text/plain": "31965"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "results_validation_data.count()"}, {"cell_type": "code", "execution_count": 25, "id": "1466bc2d-27f3-43bb-9c92-fdb431a5b573", "metadata": {}, "outputs": [], "source": "predictions_tags = []"}, {"cell_type": "code", "execution_count": null, "id": "0ac0fcf2-3a1b-498c-ae66-b33ab7adac11", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:34:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:35:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:36:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:36:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:37:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:37:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:37:52 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:38:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:38:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:39:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:39:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:39:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:40:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:40:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:41:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:41:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:41:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:42:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:42:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:42:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:43:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:43:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:43:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:43:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:44:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:44:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:44:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:44:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:44:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:44:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:45:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:45:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:45:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:45:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:45:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:45:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:46:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:46:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:46:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:46:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:46:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:46:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:46:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:47:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:47:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:47:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:47:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:47:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:47:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:47:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:47:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:48:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:48:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:48:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:48:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:48:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:48:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:48:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:49:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:49:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:49:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:49:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:49:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:49:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:50:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:50:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:50:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:50:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:50:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:50:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:50:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:50:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:51:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:51:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:51:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:51:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:51:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:51:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:51:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:52:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:52:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:52:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:52:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:53:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:53:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:53:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:53:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:54:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:54:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:54:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:54:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:54:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:54:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:54:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:54:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:54:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:54:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:55:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:55:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:55:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:55:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:56:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:56:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:56:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:56:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:56:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:56:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:56:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:56:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:56:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:57:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:57:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:57:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:57:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:58:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:58:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:58:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:58:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:58:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:58:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:58:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:58:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/02 01:58:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n                                                                                \r"}], "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nfor i in range(0,50):\n    \n    #Get the tag and model for the tag\n    tag = loaded_models[i]['tag']\n    Log_reg_model = loaded_models[i]['Log_reg_htfidf_model']\n    \n    #Predict using model\n    predictions = Log_reg_model.transform(val_df)\n    \n    #Evaluate and calculate metrics \n    eval1 = MulticlassClassificationEvaluator(labelCol = tag, predictionCol = \"prediction\")\n    accuracy = eval1.evaluate(predictions, {eval1.metricName: \"accuracy\"})\n    f1_score = eval1.evaluate(predictions, {eval1.metricName: \"f1\"})\n    \n    #Save the predictions\n    predictions_column = predictions.select(\"post_body_text\",col(\"prediction\").alias(tag))\n    predictions_column = predictions_column.withColumnRenamed(\"post_body_text\",f\"post_body_text_{i}\")\n    \n    predictions_tags.append({\n        \"tag\":tag,\n        \"predictions_column\":predictions_column,\n        \"count_rows\":predictions_column.count(),\n        \"accuracy\":accuracy,\n        \"f1_score\":f1_score\n    })"}, {"cell_type": "code", "execution_count": null, "id": "398f2ef6-9b03-4ac1-bc69-7be79b482f64", "metadata": {}, "outputs": [{"data": {"text/plain": "[{'tag': 'java',\n  'predictions_column': DataFrame[post_body_text_0: string, java: double],\n  'count_rows': 31965,\n  'accuracy': 0.879600238851001,\n  'f1_score': 0.8679389401111208},\n {'tag': 'c#',\n  'predictions_column': DataFrame[post_body_text_1: string, c#: double],\n  'count_rows': 31855,\n  'accuracy': 0.8687890882805871,\n  'f1_score': 0.8515350977618873},\n {'tag': 'javascript',\n  'predictions_column': DataFrame[post_body_text_2: string, javascript: double],\n  'count_rows': 31855,\n  'accuracy': 0.8974826361607844,\n  'f1_score': 0.8836549453457717},\n {'tag': 'php',\n  'predictions_column': DataFrame[post_body_text_3: string, php: double],\n  'count_rows': 31855,\n  'accuracy': 0.924070523900814,\n  'f1_score': 0.916029075649772},\n {'tag': 'c++',\n  'predictions_column': DataFrame[post_body_text_4: string, c++: double],\n  'count_rows': 32032,\n  'accuracy': 0.9201420534900531,\n  'f1_score': 0.9065470455473275},\n {'tag': 'jquery',\n  'predictions_column': DataFrame[post_body_text_5: string, jquery: double],\n  'count_rows': 32032,\n  'accuracy': 0.9335302806499262,\n  'f1_score': 0.925943814016528},\n {'tag': 'html',\n  'predictions_column': DataFrame[post_body_text_6: string, html: double],\n  'count_rows': 32039,\n  'accuracy': 0.9335931361764983,\n  'f1_score': 0.922778410290219},\n {'tag': 'python',\n  'predictions_column': DataFrame[post_body_text_7: string, python: double],\n  'count_rows': 32039,\n  'accuracy': 0.9469185078097991,\n  'f1_score': 0.9412964652387685},\n {'tag': 'css',\n  'predictions_column': DataFrame[post_body_text_8: string, css: double],\n  'count_rows': 32038,\n  'accuracy': 0.9626952449794148,\n  'f1_score': 0.9595620259131539},\n {'tag': 'android',\n  'predictions_column': DataFrame[post_body_text_9: string, android: double],\n  'count_rows': 32039,\n  'accuracy': 0.9662151544674565,\n  'f1_score': 0.9628272178577086},\n {'tag': 'c',\n  'predictions_column': DataFrame[post_body_text_10: string, c: double],\n  'count_rows': 32024,\n  'accuracy': 0.9492127345296836,\n  'f1_score': 0.9400854502573984},\n {'tag': 'sql',\n  'predictions_column': DataFrame[post_body_text_11: string, sql: double],\n  'count_rows': 32024,\n  'accuracy': 0.9585782079889374,\n  'f1_score': 0.9536426938740109},\n {'tag': 'mysql',\n  'predictions_column': DataFrame[post_body_text_12: string, mysql: double],\n  'count_rows': 32024,\n  'accuracy': 0.9636380778779974,\n  'f1_score': 0.9566253716525295},\n {'tag': 'arrays',\n  'predictions_column': DataFrame[post_body_text_13: string, arrays: double],\n  'count_rows': 32024,\n  'accuracy': 0.9668122819698922,\n  'f1_score': 0.9603931832177421},\n {'tag': 'string',\n  'predictions_column': DataFrame[post_body_text_14: string, string: double],\n  'count_rows': 32024,\n  'accuracy': 0.9646751940664383,\n  'f1_score': 0.9610596410048942},\n {'tag': 'sql-server',\n  'predictions_column': DataFrame[post_body_text_15: string, sql-server: double],\n  'count_rows': 32024,\n  'accuracy': 0.9760834721392878,\n  'f1_score': 0.9711568045111357},\n {'tag': 'iphone',\n  'predictions_column': DataFrame[post_body_text_16: string, iphone: double],\n  'count_rows': 32024,\n  'accuracy': 0.9768377384581539,\n  'f1_score': 0.9722861714662575},\n {'tag': 'ios',\n  'predictions_column': DataFrame[post_body_text_17: string, ios: double],\n  'count_rows': 32024,\n  'accuracy': 0.9780634212263113,\n  'f1_score': 0.9744485922685505},\n {'tag': 'regex',\n  'predictions_column': DataFrame[post_body_text_18: string, regex: double],\n  'count_rows': 32024,\n  'accuracy': 0.9810176309752034,\n  'f1_score': 0.9792830815277517},\n {'tag': 'objective-c',\n  'predictions_column': DataFrame[post_body_text_19: string, objective-c: double],\n  'count_rows': 32102,\n  'accuracy': 0.9775291492504479,\n  'f1_score': 0.9736200421232564},\n {'tag': 'algorithm',\n  'predictions_column': DataFrame[post_body_text_20: string, algorithm: double],\n  'count_rows': 32102,\n  'accuracy': 0.9806404978157705,\n  'f1_score': 0.9771162427546618},\n {'tag': 'ruby',\n  'predictions_column': DataFrame[post_body_text_21: string, ruby: double],\n  'count_rows': 32101,\n  'accuracy': 0.9819918916370722,\n  'f1_score': 0.9801871226209481},\n {'tag': 'performance',\n  'predictions_column': DataFrame[post_body_text_22: string, performance: double],\n  'count_rows': 32101,\n  'accuracy': 0.9840032684873817,\n  'f1_score': 0.9800026835188075},\n {'tag': 'database',\n  'predictions_column': DataFrame[post_body_text_23: string, database: double],\n  'count_rows': 32102,\n  'accuracy': 0.9826204469027939,\n  'f1_score': 0.9777394508096595},\n {'tag': 'linux',\n  'predictions_column': DataFrame[post_body_text_24: string, linux: double],\n  'count_rows': 31899,\n  'accuracy': 0.9821490304535027,\n  'f1_score': 0.978664216683611},\n {'tag': 'ruby-on-rails',\n  'predictions_column': DataFrame[post_body_text_25: string, ruby-on-rails: double],\n  'count_rows': 31899,\n  'accuracy': 0.9879945944247148,\n  'f1_score': 0.9867101329948968},\n {'tag': 'windows',\n  'predictions_column': DataFrame[post_body_text_26: string, windows: double],\n  'count_rows': 31899,\n  'accuracy': 0.9864860617869826,\n  'f1_score': 0.9833381236515161},\n {'tag': 'list',\n  'predictions_column': DataFrame[post_body_text_27: string, list: double],\n  'count_rows': 31899,\n  'accuracy': 0.9860775008642635,\n  'f1_score': 0.9835723703051941},\n {'tag': 'multithreading',\n  'predictions_column': DataFrame[post_body_text_28: string, multithreading: double],\n  'count_rows': 31899,\n  'accuracy': 0.98771174455514,\n  'f1_score': 0.9854432057948753},\n {'tag': 'oop',\n  'predictions_column': DataFrame[post_body_text_29: string, oop: double],\n  'count_rows': 31899,\n  'accuracy': 0.9865803450768409,\n  'f1_score': 0.9828498378087229},\n {'tag': 'bash',\n  'predictions_column': DataFrame[post_body_text_30: string, bash: double],\n  'count_rows': 31899,\n  'accuracy': 0.9889059995600114,\n  'f1_score': 0.9874949811850678},\n {'tag': 'eclipse',\n  'predictions_column': DataFrame[post_body_text_31: string, eclipse: double],\n  'count_rows': 31899,\n  'accuracy': 0.9907602375938904,\n  'f1_score': 0.9893291343797486},\n {'tag': 'ajax',\n  'predictions_column': DataFrame[post_body_text_32: string, ajax: double],\n  'count_rows': 31899,\n  'accuracy': 0.9888431440334391,\n  'f1_score': 0.9869645293333669},\n {'tag': 'perl',\n  'predictions_column': DataFrame[post_body_text_33: string, perl: double],\n  'count_rows': 31899,\n  'accuracy': 0.9890631383764418,\n  'f1_score': 0.987799262606162},\n {'tag': 'json',\n  'predictions_column': DataFrame[post_body_text_34: string, json: double],\n  'count_rows': 31899,\n  'accuracy': 0.9907288098306044,\n  'f1_score': 0.9899700736148151},\n {'tag': 'pointers',\n  'predictions_column': DataFrame[post_body_text_35: string, pointers: double],\n  'count_rows': 31899,\n  'accuracy': 0.9899745435117383,\n  'f1_score': 0.9882071693026883},\n {'tag': 'visual-studio',\n  'predictions_column': DataFrame[post_body_text_36: string, visual-studio: double],\n  'count_rows': 31899,\n  'accuracy': 0.990980231936893,\n  'f1_score': 0.9889212172811278},\n {'tag': 'xml',\n  'predictions_column': DataFrame[post_body_text_37: string, xml: double],\n  'count_rows': 31899,\n  'accuracy': 0.9899745435117383,\n  'f1_score': 0.9901516750934045},\n {'tag': 'winforms',\n  'predictions_column': DataFrame[post_body_text_38: string, winforms: double],\n  'count_rows': 31899,\n  'accuracy': 0.9896602658788775,\n  'f1_score': 0.9884476581420315},\n {'tag': 'linq',\n  'predictions_column': DataFrame[post_body_text_39: string, linq: double],\n  'count_rows': 31899,\n  'accuracy': 0.9907288098306044,\n  'f1_score': 0.9898121849582103},\n {'tag': 'function',\n  'predictions_column': DataFrame[post_body_text_40: string, function: double],\n  'count_rows': 31899,\n  'accuracy': 0.9894716992991609,\n  'f1_score': 0.9872990287116282},\n {'tag': 'class',\n  'predictions_column': DataFrame[post_body_text_41: string, class: double],\n  'count_rows': 31899,\n  'accuracy': 0.9906659543040321,\n  'f1_score': 0.9882440262239363},\n {'tag': 'tsql',\n  'predictions_column': DataFrame[post_body_text_42: string, tsql: double],\n  'count_rows': 31899,\n  'accuracy': 0.9911059429900374,\n  'f1_score': 0.9896128987544923},\n {'tag': 'wpf',\n  'predictions_column': DataFrame[post_body_text_43: string, wpf: double],\n  'count_rows': 31899,\n  'accuracy': 0.9924259090480531,\n  'f1_score': 0.9922651970628193},\n {'tag': 'xcode',\n  'predictions_column': DataFrame[post_body_text_44: string, xcode: double],\n  'count_rows': 31899,\n  'accuracy': 0.9927716144442,\n  'f1_score': 0.9909144792674044},\n {'tag': 'language-agnostic',\n  'predictions_column': DataFrame[post_body_text_45: string, language-agnostic: double],\n  'count_rows': 31899,\n  'accuracy': 0.9914202206228983,\n  'f1_score': 0.9889567706396908},\n {'tag': 'asp_dot_net',\n  'predictions_column': DataFrame[post_body_text_46: string, asp_dot_net: double],\n  'count_rows': 31899,\n  'accuracy': 0.9680379647380496,\n  'f1_score': 0.9657306089651932},\n {'tag': 'asp_dot_net-mvc',\n  'predictions_column': DataFrame[post_body_text_47: string, asp_dot_net-mvc: double],\n  'count_rows': 31899,\n  'accuracy': 0.9896916936421635,\n  'f1_score': 0.9879338438139792},\n {'tag': 'vb_dot_net',\n  'predictions_column': DataFrame[post_body_text_48: string, vb_dot_net: double],\n  'count_rows': 31899,\n  'accuracy': 0.9913573650963261,\n  'f1_score': 0.9898470510083726},\n {'tag': 'dot_net',\n  'predictions_column': DataFrame[post_body_text_49: string, dot_net: double],\n  'count_rows': 31899,\n  'accuracy': 0.9454414029353531,\n  'f1_score': 0.9309138398420905}]"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "predictions_tags"}, {"cell_type": "code", "execution_count": 29, "id": "40a6e677-c0f3-44b9-8319-6b7b9ec2ebc3", "metadata": {}, "outputs": [{"data": {"text/plain": "'java'"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "predictions_tags[0][\"tag\"]"}, {"cell_type": "code", "execution_count": 30, "id": "426ff0d7-494b-4fbe-afa1-8f7d4a512d49", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------------+------------------+------------------+\n|tag              |accuracy          |f1_score          |\n+-----------------+------------------+------------------+\n|java             |0.879600238851001 |0.8679389401111208|\n|c#               |0.8687890882805871|0.8515350977618873|\n|javascript       |0.8974826361607844|0.8836549453457717|\n|php              |0.924070523900814 |0.916029075649772 |\n|c++              |0.9201420534900531|0.9065470455473275|\n|jquery           |0.9335302806499262|0.925943814016528 |\n|html             |0.9335931361764983|0.922778410290219 |\n|python           |0.9469185078097991|0.9412964652387685|\n|css              |0.9626952449794148|0.9595620259131539|\n|android          |0.9662151544674565|0.9628272178577086|\n|c                |0.9492127345296836|0.9400854502573984|\n|sql              |0.9585782079889374|0.9536426938740109|\n|mysql            |0.9636380778779974|0.9566253716525295|\n|arrays           |0.9668122819698922|0.9603931832177421|\n|string           |0.9646751940664383|0.9610596410048942|\n|sql-server       |0.9760834721392878|0.9711568045111357|\n|iphone           |0.9768377384581539|0.9722861714662575|\n|ios              |0.9780634212263113|0.9744485922685505|\n|regex            |0.9810176309752034|0.9792830815277517|\n|objective-c      |0.9775291492504479|0.9736200421232564|\n|algorithm        |0.9806404978157705|0.9771162427546618|\n|ruby             |0.9819918916370722|0.9801871226209481|\n|performance      |0.9840032684873817|0.9800026835188075|\n|database         |0.9826204469027939|0.9777394508096595|\n|linux            |0.9821490304535027|0.978664216683611 |\n|ruby-on-rails    |0.9879945944247148|0.9867101329948968|\n|windows          |0.9864860617869826|0.9833381236515161|\n|list             |0.9860775008642635|0.9835723703051941|\n|multithreading   |0.98771174455514  |0.9854432057948753|\n|oop              |0.9865803450768409|0.9828498378087229|\n|bash             |0.9889059995600114|0.9874949811850678|\n|eclipse          |0.9907602375938904|0.9893291343797486|\n|ajax             |0.9888431440334391|0.9869645293333669|\n|perl             |0.9890631383764418|0.987799262606162 |\n|json             |0.9907288098306044|0.9899700736148151|\n|pointers         |0.9899745435117383|0.9882071693026883|\n|visual-studio    |0.990980231936893 |0.9889212172811278|\n|xml              |0.9899745435117383|0.9901516750934045|\n|winforms         |0.9896602658788775|0.9884476581420315|\n|linq             |0.9907288098306044|0.9898121849582103|\n|function         |0.9894716992991609|0.9872990287116282|\n|class            |0.9906659543040321|0.9882440262239363|\n|tsql             |0.9911059429900374|0.9896128987544923|\n|wpf              |0.9924259090480531|0.9922651970628193|\n|xcode            |0.9927716144442   |0.9909144792674044|\n|language-agnostic|0.9914202206228983|0.9889567706396908|\n|asp_dot_net      |0.9680379647380496|0.9657306089651932|\n|asp_dot_net-mvc  |0.9896916936421635|0.9879338438139792|\n|vb_dot_net       |0.9913573650963261|0.9898470510083726|\n|dot_net          |0.9454414029353531|0.9309138398420905|\n+-----------------+------------------+------------------+\n\n"}], "source": "from pyspark.sql import Row\n\n#Convert results to PySpark DataFrame\nmetrics_data = sc.parallelize([\n    Row(\n        tag=predictions_tag[\"tag\"],\n        accuracy=predictions_tag[\"accuracy\"],\n        f1_score=predictions_tag[\"f1_score\"]\n    )\n    for predictions_tag in predictions_tags\n])\n\nmetrics_df = spark.createDataFrame(metrics_data)\nmetrics_df.show(50,truncate=False)"}, {"cell_type": "code", "execution_count": 44, "id": "a2eb794f-9030-442d-9aff-30fa66d2395c", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tag</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>java</td>\n      <td>0.879600</td>\n      <td>0.867939</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c#</td>\n      <td>0.868789</td>\n      <td>0.851535</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>javascript</td>\n      <td>0.897483</td>\n      <td>0.883655</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>php</td>\n      <td>0.924071</td>\n      <td>0.916029</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c++</td>\n      <td>0.920142</td>\n      <td>0.906547</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "          tag  accuracy  f1_score\n0        java  0.879600  0.867939\n1          c#  0.868789  0.851535\n2  javascript  0.897483  0.883655\n3         php  0.924071  0.916029\n4         c++  0.920142  0.906547"}, "execution_count": 44, "metadata": {}, "output_type": "execute_result"}], "source": "evaluation_metrics_df = metrics_df.toPandas()\nevaluation_metrics_df.head()"}, {"cell_type": "code", "execution_count": 46, "id": "e7d59494-2371-427b-8f8a-84d36f483890", "metadata": {}, "outputs": [], "source": "evaluation_metrics_df.to_csv('evaluation_metrics_df.csv',index=False)"}, {"cell_type": "code", "execution_count": 47, "id": "f8b424dc-c8f1-420e-ac5a-81efa27adae3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Copying file://evaluation_metrics_df.csv [Content-Type=text/csv]...\n/ [1/1 files][  2.2 KiB/  2.2 KiB] 100% Done                                    \nOperation completed over 1 objects/2.2 KiB.                                      \n"}], "source": "!gsutil -m cp 'evaluation_metrics_df.csv' 'gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/'"}, {"cell_type": "code", "execution_count": null, "id": "0c9ab38d-1382-44e2-9936-56d99f02572b", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "7de673a2-f440-4696-aa1e-9a982e7eec10", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}